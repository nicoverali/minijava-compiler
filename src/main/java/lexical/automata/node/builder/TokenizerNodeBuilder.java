package lexical.automata.node.builder;

import lexical.Lexeme;
import lexical.Token;
import lexical.TokenType;
import lexical.automata.AutomataToken;
import lexical.automata.NodeBranch;
import lexical.automata.LexicalNode;
import lexical.automata.branch.CharacterLexemePrependBranch;
import lexical.automata.filter.LexicalFilter;
import lexical.automata.node.DefaultLexicalNode;
import lexical.automata.node.strategy.LexicalErrorStrategy;
import lexical.automata.node.strategy.TokenizeStrategy;

public class TokenizerNodeBuilder extends BaseLexicalNodeBuilder<TokenizerNodeBuilder.TokenizerBranchBuilder>{

    private final DefaultLexicalNode<AutomataToken> buildingNode;

    public TokenizerNodeBuilder(String nodeName){
        buildingNode = new DefaultLexicalNode<>(nodeName);
    }

    @Override
    protected TokenizerBranchBuilder createBranchBuilder(LexicalFilter filter) {
        return new TokenizerBranchBuilder(filter, this);
    }

    /**
     * Makes the {@link LexicalNode} being built return a {@link Token} of the specified type whenever it cannot
     * delegate the processing of characters.
     *
     * @param type {@link TokenType} of tokens returned by the {@link LexicalNode} being built
     * @return a node builder to keep building the node
     */
    public LexicalNode<AutomataToken> orElseReturnToken(TokenType type){
        buildingNode.setStrategy(new TokenizeStrategy(type));
        return buildingNode;
    }

    /**
     * Makes the {@link LexicalNode} being built to throw a {@link lexical.LexicalException} whenever it cannot
     * delegate the processing of characters
     *
     * @param msg the message of all {@link lexical.LexicalException} thrown by the {@link LexicalNode} being built
     * @return a node builder to keep building the node
     */
    public LexicalNode<AutomataToken> orElseThrow(String msg){
        buildingNode.setStrategy(new LexicalErrorStrategy<>(msg));
        return buildingNode;
    }

    public class TokenizerBranchBuilder extends BaseLexicalNodeBuilder.BaseNodeBranchBuilder<TokenizerNodeBuilder, AutomataToken> {


        public TokenizerBranchBuilder(LexicalFilter filter, TokenizerNodeBuilder nodeBuilder) {
            super(filter, nodeBuilder);
        }

        /**
         * Makes the {@link NodeBranch} being built prepend the characters it receives to
         * the {@link Lexeme} generated by the next node of the branch.
         *
         * @return this branch builder to end the branch creation
         */
        public BaseNodeBranchBuilder<TokenizerNodeBuilder, AutomataToken> storeInLexeme(){
            buildingBranch = new CharacterLexemePrependBranch(buildingBranch);
            return this;
        }

        @Override
        protected LexicalNode<AutomataToken> getBuildingNode() {
            return buildingNode;
        }

    }

}
